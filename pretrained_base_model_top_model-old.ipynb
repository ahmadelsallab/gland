{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import sys, os, multiprocessing, urllib.request, urllib.error, urllib.parse, requests csv\n",
    "import sys, os, multiprocessing, requests, csv\n",
    "from PIL import Image\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load meta data csv into DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataFrame loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b2bb500b6a38aa0</td>\n",
       "      <td>http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...</td>\n",
       "      <td>11284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "2  6b2bb500b6a38aa0  http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  \n",
       "2        11284  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data frame\n",
    "train_data_path = '../../dat/train.csv'\n",
    "all_train_df = pd.read_csv(train_data_path)\n",
    "print('Training DataFrame loaded')\n",
    "all_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataFrame loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000088da12d664db</td>\n",
       "      <td>https://lh3.googleusercontent.com/-k45wfamuhT8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001623c6d808702</td>\n",
       "      <td>https://lh3.googleusercontent.com/-OQ0ywv8KVIA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001bbb682d45002</td>\n",
       "      <td>https://lh3.googleusercontent.com/-kloLenz1xZk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url\n",
       "0  000088da12d664db  https://lh3.googleusercontent.com/-k45wfamuhT8...\n",
       "1  0001623c6d808702  https://lh3.googleusercontent.com/-OQ0ywv8KVIA...\n",
       "2  0001bbb682d45002  https://lh3.googleusercontent.com/-kloLenz1xZk..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_path = '../../dat/test.csv'\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "print('Test DataFrame loaded')\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random split train into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(all_train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histo of classes in train/va/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/val/test folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missing classes from val or test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ALL class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '../../dat/train/'\n",
    "val_dir = '../../dat/val/'\n",
    "test_dir = '../../dat/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_out_dir(base, x):\n",
    "    return base+x\n",
    "\n",
    "def create_data_folder(base_dir, df):    \n",
    "    if not os.path.exists(base_dir):\n",
    "        os.mkdir(base_dir)    \n",
    "    if 'landmark_id' in df.columns:\n",
    "        df['out_dir'] = df['landmark_id'].apply(lambda x: gen_out_dir(base_dir, str(x)))\n",
    "        for out_dir in df['out_dir']:\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.mkdir(out_dir)\n",
    "    else:\n",
    "        df['out_dir'] = base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "create_data_folder(train_dir, train_df)\n",
    "create_data_folder(val_dir, val_df)\n",
    "create_data_folder(test_dir, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def download(df, data_dir):\n",
    "    \n",
    "    #key_url_list = list(df['url'])d\n",
    "    \n",
    "    Loop on img_files in df\n",
    "        Open class_lbl data_dir\n",
    "        if file exists:\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                download\n",
    "                Mark file exists in df\n",
    "\n",
    "            except:\n",
    "                Mark file missing in df\n",
    "'''                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-1:\n",
      "AttributeError: 'module' object has no attribute 'copy_image'\n",
      "Process PoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    task = get()\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    return recv()\n",
      "    return recv()\n",
      "AttributeError: 'module' object has no attribute 'copy_image'\n",
      "Process PoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    return recv()\n",
      "AttributeError: 'module' object has no attribute 'copy_image'\n"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool(processes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_str = 'train_df'\n",
    "#eval_df = pd.DataFrame()\n",
    "#exec(\"%s = %s\" % (eval_df, df_str))\n",
    "eval_df = eval(df_str)\n",
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_entry(args):\n",
    "    col, d = args\n",
    "    print(d.head(3))\n",
    "    \n",
    "pool.map(print_entry, [(d, kwargs) for d in train_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def download_image(data):\n",
    "  \n",
    "    key_url = data[0]\n",
    "    (key, url) = key_url\n",
    "    out_dir = data[1]\n",
    "    filename = os.path.join(out_dir, '%s.jpg' % key)\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        print(('Image %s already exists. Skipping download.' % filename))\n",
    "        return\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url)\n",
    "        image_data = response.read()\n",
    "        # Save file (TODO)\n",
    "        # Mark file exists in df (TODO) return True\n",
    "\n",
    "    except:\n",
    "        # Mark file missing in df (TODO) return False\n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def download_image(df_str):\n",
    "    df = eval(df_str)\n",
    "    key_url = df['url']\n",
    "    (key, url) = key_url\n",
    "    out_dir = df['out_dir']\n",
    "    filename = os.path.join(out_dir, '%s.jpg' % key)\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        df['exists'] = True\n",
    "        print(('Image %s already exists. Skipping download.' % filename))\n",
    "        return\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url)\n",
    "        image_data = response.read()\n",
    "        # Save file (TODO)\n",
    "        # Mark file exists in df\n",
    "        df['exists'] = True\n",
    "\n",
    "    except:\n",
    "        # Mark file missing in df (TODO)\n",
    "        df['exists'] = False\n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_image(args):\n",
    "    df_str, loc = args\n",
    "    df = eval(df_str).iloc[loc]\n",
    "    key_url = df['url']\n",
    "    (key, url) = key_url\n",
    "    out_dir = df['out_dir']\n",
    "    filename = os.path.join(out_dir, '%s.jpg' % key)\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        df['exists'] = True\n",
    "        print(('Image %s already exists. Skipping download.' % filename))\n",
    "        return\n",
    "    try:\n",
    "        #response = urllib.request.urlopen(url)\n",
    "        #mage_data = response.read()\n",
    "        image_data = requests.get(url, stream=True)\n",
    "        \n",
    "        # Save file\n",
    "        try:\n",
    "            with open(filename, 'wb') as out_file:\n",
    "            shutil.copyfileobj(image_data.raw, out_file)\n",
    "            out_file.close()\n",
    "            del response\n",
    "\n",
    "        except:\n",
    "            print(('Warning: Failed to save image %s' % filename))\n",
    "            return\n",
    "\n",
    "        # Mark file exists in df\n",
    "        df['exists'] = True\n",
    "\n",
    "    except:\n",
    "        # Mark file missing in df\n",
    "        df['exists'] = False\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(df_str):\n",
    "    df = eval(df_str)\n",
    "    key_url = df['url']\n",
    "    (key, url) = key_url\n",
    "    out_dir = df['out_dir']\n",
    "    filename = os.path.join(out_dir, '%s.jpg' % key)\n",
    "    print(key)\n",
    "    print(url)\n",
    "    print(file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool.map(test, 'train_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#train_d = zip(list(train_df['url']), list(train_df['out_dir']))\n",
    "#train_df['exists'] = pool.map(download_image, train_d)\n",
    "#pool.map(download_image, 'train_df')\n",
    "args = zip(('train_df', range(len(train_df))))\n",
    "pool.map(download_image, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_d = zip(list(train_df['url']), list(val_d['out_dir']))\n",
    "#pool.map(download_image, val_d)\n",
    "# pool.map(download_image, 'val_df')\n",
    "args = zip(('val_df', range(len(val_df))))\n",
    "pool.map(download_image, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_d = zip(list(train_df['url']), list(val_d['out_dir']))\n",
    "#pool.map(download_image, val_d)\n",
    "# pool.map(download_image, 'val_df')\n",
    "args = zip(('test_df', range(len(test_df))))\n",
    "pool.map(download_image, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy data into their class folders (ONLY needed if data is downloaded in flat folders first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_image(args):\n",
    "    df_str, flat_dir, loc = args\n",
    "    print args\n",
    "    df = eval(df_str).iloc[loc]\n",
    "    key_url = df['url']\n",
    "    (key, url) = key_url\n",
    "    out_dir = df['out_dir']    \n",
    "    \n",
    "    src_filename = os.path.join(flat_dir, '%s.jpg' % key)\n",
    "    \n",
    "    filename = os.path.join(out_dir, '%s.jpg' % key)\n",
    "    if os.path.exists(filename):\n",
    "        df['exists'] = True\n",
    "        print(('Image %s already exists. Skipping copy.' % filename))\n",
    "        return    \n",
    "\n",
    "    try:\n",
    "        # Copy file\n",
    "        shutil.copyfile(src_filename, out_dir)\n",
    "\n",
    "        # Mark file exists in df\n",
    "        df['exists'] = True\n",
    "        print(('Image %s copied.' % filename))\n",
    "\n",
    "    except:\n",
    "        print(('Image %s does not exist.' % filename))\n",
    "        # Mark file missing in df\n",
    "        df['exists'] = False\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_folder_path = '../../dat/all_train_raw'\n",
    "args = zip(('train_df', flat_folder_path, range(len(train_df))))\n",
    "#args = zip(('train_df', flat_folder_path, 100))\n",
    "#print len(train_df)\n",
    "#df_str, flat_dir, loc = args\n",
    "#print(loc)\n",
    "pool.map(copy_image, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_folder_path = '../../dat/all_train_raw' # All train and val data is in one folder. The url and out_dir colomn in the df will specify if its train or val according to the split.\n",
    "args = zip(('val_df', flat_folder_path, range(len(val_df))))\n",
    "pool.map(copy_image, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_folder_path = '../../dat/all_train_raw'\n",
    "args = zip(('test_df', flat_folder_path, range(len(test_df))))\n",
    "pool.map(copy_image, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Top model pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Top model + top base layers fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
